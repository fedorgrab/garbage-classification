# -*- coding: utf-8 -*-
"""InceptionV3_vf.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nw6TsLDf_0BMBDMw0A3DXCfb7eBL5yp-

# **Garbage classification:** InceptionV3

## Installing libraries
"""

#Import necessary libraries
from keras.applications.inception_v3 import InceptionV3
from keras_preprocessing.image import ImageDataGenerator
import keras
from keras.models import Sequential
from keras import optimizers, losses
from keras.layers import Conv2D, Flatten, MaxPooling2D, Dense, Dropout, GlobalAveragePooling2D
from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau
import pickle
from keras.layers.convolutional import Convolution2D, MaxPooling2D
from google.colab import drive, files
import os
from sklearn.metrics import confusion_matrix, classification_report
import numpy as np
from skimage.io import imread_collection
import matplotlib.pyplot as plt
import pandas as pd
from keras.models import load_model
import random

"""## Data preparation

### Mount Drive
"""

#Mount Google Drive
drive.mount('/content/drive')
""
#Assign directory path for test, train and validation data
test_data_dir = '/content/drive/My Drive/split-garbage-dataset/split-garbage-dataset/test'
train_data_dir = '/content/drive/My Drive/split-garbage-dataset/split-garbage-dataset/train'
valid_data_dir = '/content/drive/My Drive/split-garbage-dataset/split-garbage-dataset/valid'

"""### Load data as ImageDataGenerator and images"""

#Define labels
LABELS = ["trash", "plastic", "paper", "metal", "glass", "cardboard"]
#Define dictionary
LABELS_NUMBERS_MAP = {k:v for k,v in zip(LABELS, range(len(LABELS)))}
#Define reverse of dictionary
LABELS_NUMBERS_REVERSE ={v: k for k, v in LABELS_NUMBERS_MAP.items()}

#Load images as ImageDataGenerator with augmentation
train_generator = ImageDataGenerator(
        horizontal_flip=True,
        vertical_flip=True,
        rescale=1. / 255,
        shear_range=0.1,
        zoom_range=0.1,
        width_shift_range=0.1,
        height_shift_range=0.1,
        rotation_range=40,
    ).flow_from_directory(
        directory=train_data_dir,
        target_size=(300, 300),
        class_mode = 'categorical',
        shuffle= False,
    )

#Load validation images from directory
valid_generator = ImageDataGenerator(
        rescale=1 / 255,
    ).flow_from_directory(
        directory=valid_data_dir,
        target_size=(300, 300),
        class_mode = 'categorical',
        shuffle= False,
    )

#Load test images from test directory
test_generator = ImageDataGenerator(
        rescale=1 / 255,
    ).flow_from_directory(
        directory=test_data_dir,
        target_size=(300, 300),
        class_mode = 'categorical',
        shuffle= False,
    )

#Load images
LOAD_FILES_FROM_DRIVE = False

if not LOAD_FILES_FROM_DRIVE:
    for path in [train_data_dir, valid_data_dir, test_data_dir]:
        image_list = [
            imread_collection(f"{path}/{label}/*.jpg") for label in LABELS
        ]
        X_tmp = np.concatenate(image_list)
        y_tmp = np.concatenate([
            np.full(len(arr), i) for i, arr in enumerate(image_list)
        ])
        data_type = path.split("/")[-1]
        np.save(f"X_{data_type}.npy", X_tmp)
        np.save(f"y_{data_type}.npy", y_tmp)

X_train = np.load("X_train.npy")
y_train = np.load("y_train.npy")
X_valid = np.load("X_valid.npy")
y_valid = np.load("y_valid.npy")
X_test = np.load("X_test.npy")
y_test = np.load("y_test.npy")

"""## Understanding the data

### Visualize sample photos
"""

#Visualizing sample photos
plt.figure(figsize=[25,15])

for k,i in enumerate(np.random.randint(0, len(X_train), 5)):
    plt.subplot(1,5,k+1)
    plt.imshow(X_train[i])
    plt.xticks(())
    plt.yticks(())
    plt.title(LABELS_NUMBERS_REVERSE[y_train[i]])
    #plt.show()

"""## Build model

### Define layers
"""

#Install tf-nightly
try:
  # %tensorflow_version only exists in Colab.
  !pip install tf-nightly
except Exception:
  pass
  
import tensorflow as tf


#Define model to train the data on
base_model = InceptionV3(weights=None, include_top=False, input_shape=(300, 300, 3))
#Loading pretrained weights as Trasnsfer Learning fro Inception V3
#https://www.kaggle.com/careyai/inceptionv3-full-pretrained-model-instructions
base_model.load_weights('/content/drive/My Drive/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5')
base_model.trainable = False
#Defining layers for model
model = Sequential([
    base_model,
    GlobalAveragePooling2D(),
    Dropout(0.15),
    #Conv2D(1024,3, strides = 2, padding="same", activation='relu'),
    Dense(1024, activation='relu'),
    Dropout(0.15),
    #Flatten(),
    Dense(6, activation='softmax')
])

"""### Compile model"""

#Define optimizer and learning rate
opt = optimizers.nadam(lr=0.001)
#Compile the model
model.compile(loss="categorical_crossentropy", optimizer=opt, metrics=['accuracy'])
#Print model summary
model.summary()

"""### Train the model"""

#Define model parameters
batch_size = 200
epochs = 200
patience = 10

steps_per_epoch = train_generator.n // batch_size
validation_steps = valid_generator.n // batch_size

#Define location to store models
filepath = "/content/drive/My Drive/model/model_{epoch:02d}-{acc:.2f}-{val_acc:.2f}.h5"

#Define checkpoint layers
checkpoint1 = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=False, mode='max')
checkpoint2 = ModelCheckpoint(filepath, monitor='acc', verbose=1, save_best_only=True, mode='max')
rlrp = ReduceLROnPlateau(monitor='acc', factor=0.1, patience=patience, min_delta=0.000000001)

callbacks_list = [rlrp,checkpoint1,checkpoint2]

#Fit the data on model
history = model.fit_generator(generator=train_generator, epochs=epochs, steps_per_epoch=steps_per_epoch,
                              validation_data=valid_generator, validation_steps=validation_steps,
                              callbacks=callbacks_list)

#Download History as CSV to local drive
hist_df = pd.DataFrame(history.history) 
hist_df.to_csv('trainHistoryDict.csv')
files.download('trainHistoryDict.csv')

"""## Test the model

### Measure test accuracy of model
"""

#Load the model for required Epoch
model1 = load_model('/content/drive/My Drive/model_47-0.80-0.88.h5')

#Reset the test generator
test_generator.reset()
#Evaluate the model on test generator
history1=model1.evaluate_generator(test_generator)

#Print the test accuracy
print(f'The test accuracy of the model is: {round(history1[1]*100,2)}%')

#Get predictions on test data
Y_pred = model1.predict_generator(test_generator)
#Convert prediction scores to categorical values
y_pred = np.argmax(Y_pred, axis=1)

"""### Plot confusion matrix"""

#Print plot title
print('Confusion Matrix')
#Calculate confusion matrix
cm = confusion_matrix(test_generator.classes, y_pred)
#Define plot space
fig, ax = plt.subplots()
#Plot the confusion matrix
im = ax.imshow(cm)
#Set Xticks
ax.set_xticks(np.arange(6)), ax.set_yticks(np.arange(6))
#Define the X tick labels
ax.set_xticklabels(list(LABELS_NUMBERS_REVERSE.values()), rotation=45, ha="right")
#Define the Y tick labels
ax.set_yticklabels(list(LABELS_NUMBERS_REVERSE.values()))
#Set y label
ax.set_ylabel('True')
#Set x label
ax.set_xlabel('Predicted')
#Calculate and display values
for i in range(36):
    ax.text(int(i/6),i%6,cm[i%6,int(i/6)], ha="center", va="center", color="w")

"""### View classification report"""

#Print the classification report
print('Classification Report')
print(classification_report(test_generator.classes, y_pred, target_names=LABELS_NUMBERS_MAP))

"""### View misclassified samples"""

#Visualizing sample photos
import matplotlib.pyplot as plt
plt.figure(figsize=[25,15])
for k,i in enumerate(random.choices(np.where(y_pred != y_test)[0].tolist(),k=5)):
    plt.subplot(1,5,k+1)
    plt.imshow(X_train[i])
    plt.xticks(())
    plt.yticks(())
    plt.xlabel("True: {}, Predicted: {}".format(LABELS_NUMBERS_REVERSE[y_train[i]],LABELS_NUMBERS_REVERSE[y_test[i]]))
plt.show();